dice_url6 <-"https://www.dice.com/jobs/q-Data_Scientist-limit-30-startPage-6-limit-30-jobs?searchid=5839899086074"
dice_url7 <-"https://www.dice.com/jobs/q-Data_Scientist-limit-30-startPage-7-limit-30-jobs?searchid=5839899086074"
dice_url8 <-"https://www.dice.com/jobs/q-Data_Scientist-limit-30-startPage-8-limit-30-jobs?searchid=5839899086074"
dice_url9 <-"https://www.dice.com/jobs/q-Data_Scientist-limit-30-startPage-9-limit-30-jobs?searchid=5839899086074"
dice_url10 <-"https://www.dice.com/jobs/q-Data_Scientist-limit-30-startPage-10-limit-30-jobs?searchid=5839899086074"
dice_url11 <-"https://www.dice.com/jobs/q-Data_Scientist-limit-30-startPage-11-limit-30-jobs?searchid=5839899086074"
dice_url12 <-"https://www.dice.com/jobs/q-Data_Scientist-limit-30-startPage-12-limit-30-jobs?searchid=5839899086074"
#glassdoor_main <- getURL(gl_url, cainfo = cert, verbose = TRUE)
#glassdoor_main <- getURL(gl_url, ssl.verifypeer = FALSE, verbose = TRUE)
dice_main1 <- getURL(dice_url1, cainfo = cert, verbose = TRUE)
dice_main2 <- getURL(dice_url2, cainfo = cert, verbose = TRUE)
dice_main3 <- getURL(dice_url3, cainfo = cert, verbose = TRUE)
dice_main4 <- getURL(dice_url4, cainfo = cert, verbose = TRUE)
dice_main5 <- getURL(dice_url5, cainfo = cert, verbose = TRUE)
dice_main6 <- getURL(dice_url6, cainfo = cert, verbose = TRUE)
dice_main7 <- getURL(dice_url7, cainfo = cert, verbose = TRUE)
dice_main8 <- getURL(dice_url8, cainfo = cert, verbose = TRUE)
dice_main9 <- getURL(dice_url9, cainfo = cert, verbose = TRUE)
dice_main10 <- getURL(dice_url10, cainfo = cert, verbose = TRUE)
dice_main11 <- getURL(dice_url11, cainfo = cert, verbose = TRUE)
dice_main12 <- getURL(dice_url12, cainfo = cert, verbose = TRUE)
# get filtered result child data-set into data frame, first page
filterLinks <- getLinks()
htmlTreeParse(dice_main1, handlers = filterLinks)
df_links1 <- data.frame(filterLinks$links())
filterTitle <- getTitle()
htmlTreeParse(dice_main1, handlers = filterTitle)
df_titles1 <- data.frame(filterTitle$links())
# get filtered result child data-set into data frame, 2nd page
htmlTreeParse(dice_main2, handlers = filterLinks)
df_links2 <- data.frame(filterLinks$links())
htmlTreeParse(dice_main2, handlers = filterTitle)
df_titles2 <- data.frame(filterTitle$links())
# get filtered result child data-set into data frame, 3rd page
htmlTreeParse(dice_main3, handlers = filterLinks)
df_links3 <- data.frame(filterLinks$links())
htmlTreeParse(dice_main3, handlers = filterTitle)
df_titles3 <- data.frame(filterTitle$links())
# get filtered result child data-set into data frame, 4th page
htmlTreeParse(dice_main4, handlers = filterLinks)
df_links4 <- data.frame(filterLinks$links())
htmlTreeParse(dice_main4, handlers = filterTitle)
df_titles4 <- data.frame(filterTitle$links())
# get filtered result child data-set into data frame, 5th page
htmlTreeParse(dice_main5, handlers = filterLinks)
df_links5 <- data.frame(filterLinks$links())
htmlTreeParse(dice_main5, handlers = filterTitle)
df_titles5 <- data.frame(filterTitle$links())
# get filtered result child data-set into data frame, 6th page
htmlTreeParse(dice_main6, handlers = filterLinks)
df_links6 <- data.frame(filterLinks$links())
htmlTreeParse(dice_main6, handlers = filterTitle)
df_titles6 <- data.frame(filterTitle$links())
# get filtered result child data-set into data frame, 7th page
htmlTreeParse(dice_main7, handlers = filterLinks)
df_links7 <- data.frame(filterLinks$links())
filterTitle1 <- getTitle()
htmlTreeParse(dice_main7, handlers = filterTitle)
df_titles7 <- data.frame(filterTitle$links())
# get filtered result child data-set into data frame, 8th page
htmlTreeParse(dice_main8, handlers = filterLinks)
df_links8 <- data.frame(filterLinks$links())
htmlTreeParse(dice_main8, handlers = filterTitle)
df_titles8 <- data.frame(filterTitle$links())
# get filtered result child data-set into data frame, 9th page
htmlTreeParse(dice_main9, handlers = filterLinks)
df_links9 <- data.frame(filterLinks$links())
htmlTreeParse(dice_main9, handlers = filterTitle)
df_titles9 <- data.frame(filterTitle$links())
# get filtered result child data-set into data frame, 10th page
htmlTreeParse(dice_main10, handlers = filterLinks)
df_links10 <- data.frame(filterLinks$links())
htmlTreeParse(dice_main10, handlers = filterTitle)
df_titles10 <- data.frame(filterTitle$links())
# get filtered result child data-set into data frame, 11th page
htmlTreeParse(dice_main11, handlers = filterLinks)
df_links11 <- data.frame(filterLinks$links())
htmlTreeParse(dice_main11, handlers = filterTitle)
df_titles11 <- data.frame(filterTitle$links())
# get filtered result child data-set into data frame, 12th page
htmlTreeParse(dice_main12, handlers = filterLinks)
df_links12 <- data.frame(filterLinks$links())
htmlTreeParse(dice_main12, handlers = filterTitle)
df_titles12 <- data.frame(filterTitle$links())
df_links <- rbind(df_links1, df_links2, df_links3, df_links4, df_links5, df_links6, df_links7, df_links9, df_links10, df_links11, df_links12)
links_clean <-grep(fixed("https://www.dice.com/jobs/detail/"),df_links[,1], value = TRUE)
write.csv(links_clean, file = "dice2.csv")
detail_url <- links_clean[1]
detail_main <-getURL(detail_url, cainfo = cert, httpauth = 1, verbose = TRUE )
GET(detail_url)
install.packages("RMySQL")
head(df[, 1:5])
install.packages("wordcloud")
install.packages("RColorBrewer")
install.packages("rmarkdown")
library(RCurl)
library(stringr)
my_API_key <- "687e52456395577d652bdb3bd7ce9ec8:6:65677168"
base_url <- "http://api.nytimes.com/svc/books/v3/lists/best-sellers/history.JSON?"
my_author <- "Michael-Connelly"
my_title <- "The-Black-Echo"
search_term <- sprintf("search-author=%s&title=%s", my_author, my_title)
full_url <- paste(base_url, search_term, "&api=key=", my_API_key, sep="")
full_url
feed <- getURL(full_url)
feed <- getURL(full_url)
feed <- getURL(full_url)
str(feed)
feed
feed <- getURL(full_url)
str(feed)
my_API_key <- "687e52456395577d652bdb3bd7ce9ec8:6:65677168"
my_API_key <- "687e52456395577d652bdb3bd7ce9ec8:6:65677168"
base_url <- "http://api.nytimes.com/svc/books/v3/lists/best-sellers/history.JSON?"
my_author <- "Michael-Connelly"
my_title <- "The-Black-Echo"
search_term <- sprintf("search-author=%s&title=%s", my_author, my_title)
full_url <- paste(base_url, search_term, "&api=key=", my_API_key, sep="")
feed <- getURL(full_url)
str(feed)
my_API_key <- "687e52456395577d652bdb3bd7ce9ec8:6:65677168"
base_url <- "http://api.nytimes.com/svc/books/v3/lists/best-sellers/history.JSON?"
my_author <- "Michael+Connelly"
my_title <- "The+Black+Echo"
search_term <- sprintf("search-author=%s&title=%s", my_author, my_title)
full_url <- paste(base_url, search_term, "&api=key=", my_API_key, sep="")
feed <- getURL(full_url)
str(feed)
my_API_key <- "687e52456395577d652bdb3bd7ce9ec8:6:65677168"
base_url <- "http://api.nytimes.com/svc/books/v3/lists/best-sellers/history.JSON?"
my_author <- "Michael%2BConnelly"
my_title <- "The%2BBlack%2BEcho"
search_term <- sprintf("search-author=%s&title=%s", my_author, my_title)
full_url <- paste(base_url, search_term, "&api=key=", my_API_key, sep="")
full_url
feed <- getURL(full_url)
str(feed)
feed <- getForm(full_url)
test_url <- "http://api.nytimes.com/svc/books/v3/lists/names.json?api-key=687e52456395577d652bdb3bd7ce9ec8%3A6%3A65677168"
feed <- getURL(test_url)
str(feed)
feed
library(jsonlite)
df <- fromJSON(feed)
df
test2_url <- "http://api.nytimes.com/svc/books/v3/lists/Chapter-Books.json?sort-by=rank&sort-order=ASC&api-key=687e52456395577d652bdb3bd7ce9ec8%3A6%3A65677168"
feed2 <- getURL(test2_url)
df2 <- fromJSON(feed2)
df2
p_c <- 0.08
n_c <- 11545
p_o <- 0,088
n_o <- 4691
se_c_o <- sqrt((p_c*(1-p_c))/n_c + (p_o*(1-p_o))/n_o)
p_c <- 0.08
n_c <- 11545
p_o <- 0.088
n_o <- 4691
se_c_o <- sqrt((p_c*(1-p_c))/n_c + (p_o*(1-p_o))/n_o)
se_c_o <- sqrt((p_c*(1-p_c))/n_c + (p_o*(1-p_o))/n_o)
interval_p_c_low <- (p_c - p_o) - 1.96 * se_c_o
interval_p_c_high <- (p_c - p_o) + 1.96 * se_c_o
interval_p_c_high
interval_p_c_low
se_c_o
p_dif <- p_o - p_c
p_dif
p_c*(1-p_c
)
p_o*(1-p_o)
(p_c*(1-p_c))/n_c
se_c_o <- sqrt((p_c*(1-p_c))/n_c + (p_o*(1-p_o))/n_o)
se_c_o
interval_p_c_low <- p_dif - 1.96 * se_c_o
interval_p_c_high <- p_dif + 1.96 * se_c_o
1.96 * se_c_o
p_dif
interval_p_c_high
interval_p_c_low
z_wood <- (o_wood-e_wood)/sqrt(e_wood)
z_cul <- (o_cul-e_cul)/sqrt(e_cul)
z_deci <- (o_deci-e_deci)/sqrt(e_deci)
z_oth <- (o_oth-e_oth)/sqrt(e_oth)
df <- 4-1
e_wood <- 20.5
e_cul <- 62.6
e_deci <- 168.7
e_oth <- 174.2
o_wood <- 4
o_cul <- 16
o_deci <-67
o_oth <- 345
z_wood <- (o_wood-e_wood)/sqrt(e_wood)
z_cul <- (o_cul-e_cul)/sqrt(e_cul)
z_deci <- (o_deci-e_deci)/sqrt(e_deci)
z_oth <- (o_oth-e_oth)/sqrt(e_oth)
x <- z_wood^2 + z_cul^2 + z_deci^2 + z_oth^2
x
9.41/10.37 * 0.67
171.14 - (0.61 * 107.20)
0.61^2
library(RCurl)
library(XML)
# Extract review from NYT given URL
movie_url <- http:\/\/www.nytimes.com\/2016\/04\/22\/movies\/review-the-huntsman-a-study-in-hollywoods-overstuffed-playbook.html
# helper function
getContent <- function() {
links <- character()
list(a = function(node, ...) {
links <<- c(links, xmlGetAttr(node, "story-body-text story-content"))
node
},
links = function()links)
}
nyt_review <- getURL(movie_url, ssl.verifypeer = FALSE, verbose = TRUE)
movie_url <- "http:\/\/www.nytimes.com\/2016\/04\/22\/movies\/review-the-huntsman-a-study-in-hollywoods-overstuffed-playbook.html"
# helper function
getContent <- function() {
links <- character()
list(a = function(node, ...) {
links <<- c(links, xmlGetAttr(node, "story-body-text story-content"))
node
},
links = function()links)
}
nyt_review <- getURL(movie_url, ssl.verifypeer = FALSE, verbose = TRUE)
filterContent <- getContent()
htmlTreeParse(nyt_review, handlers = filterContent)
nyt_review <- getURL(movie_url, ssl.verifypeer = FALSE, verbose = TRUE)
filterContent <- getContent()
htmlTreeParse(nyt_review, handlers = filterContent)
movie_url
movie_url <- "http:\/\/www.nytimes.com\/2016\/04\/22\/movies\/review-the-huntsman-a-study-in-hollywoods-overstuffed-playbook.html"
movie_url <- "http://www.nytimes.com/2016/04/22/movies/review-the-huntsman-a-study-in-hollywoods-overstuffed-playbook.html"
getContent <- function() {
contents <- character()
list(a = function(node, ...) {
contents <<- c(contents, xmlGetAttr(node, "story-body-text story-content"))
node
},
contents = function()contents)
}
nyt_review <- getURL(movie_url, ssl.verifypeer = FALSE, verbose = TRUE)
filterContent <- getContent()
nyt_review <- getURL(movie_url, ssl.verifypeer = FALSE, verbose = TRUE)
filterContent <- getContent()
htmlTreeParse(nyt_review, handlers = filterContent)
df_contents <- data.frame(filterContents$contents())
filterContent <- getContent()
filterContent
getContent <- function() {
links <- character()
list(a = function(node, ...) {
links <<- c(links, xmlGetAttr(node, "story-body-text story-content"))
node
},
links = function()links)
}
nyt_review <- getURL(movie_url, ssl.verifypeer = FALSE, verbose = TRUE)
filterContent <- getContent()
htmlTreeParse(nyt_review, handlers = filterContent)
filterContent
htmlTreeParse(nyt_review, handlers = filterContent)
nyt_review
getURL(movie_url, ssl.verifypeer = FALSE, verbose = TRUE)
movie_url2 <- "http://www.nytimes.com/glogin?URI=http%3A%2F%2Fwww.nytimes.com%2F2016%2F04%2F22%2Fmovies%2Freview-the-huntsman-a-study-in-hollywoods-overstuffed-playbook.html%3F_r%3D0"
nyt_review <- getURL(movie_url2, ssl.cookie = "RMID=007f010130c9572042640000;Path=/; Domain=.nytimes.com;Expires=Thu, 27 Apr 2017 04:39:00 UTC", verifypeer = FALSE, verbose = TRUE)
nyt_review <- getURL(movie_url2, cookie = "RMID=007f010130c9572042640000;Path=/; Domain=.nytimes.com;Expires=Thu, 27 Apr 2017 04:39:00 UTC", ssl.verifypeer = FALSE, verbose = TRUE)
movie_url3 <- "http://www.nytimes.com/2016/04/22/movies/review-the-huntsman-a-study-in-hollywoods-overstuffed-playbook.html?_r=0"
nyt_review3 <- getURL(movie_url3, cookie = "NYT-S=0M9dlRaPpCKE7DXrmvxADeHy7RGZbqql66deFz9JchiAIUFL2BEX5FWcV.Ynx4rkFI; expires=Fri, 27-May-2016 04:59:39 GMT; path=/; domain=.nytimes.com",
ssl.verifypeer = FALSE, verbose = TRUE)
nyt_review3
filterContent <- getContent()
htmlTreeParse(nyt_review, handlers = filterContent)
df_contents <- data.frame(filterContents$links())
filterContent <- getContent()
htmlTreeParse(nyt_review, handlers = filterContent)
filterContent
df_contents
htmlTreeParse(nyt_review3, handlers = filterContent)
df_contents <- data.frame(filterContents$links())
df_contents <- data.frame(filterContent$links())
df_contents
nyt_review3
htmlParse(nyt_review3)
htmlTreeParse(nyt_review3)
getContent <- function() {
links <- character()
list(a = function(node, ...) {
links <<- c(links, xmlGetAttr(node, "p class=story-body-text story-content"))
node
},
links = function()links)
}
filterContent <- getContent()
htmlTreeParse(nyt_review3, handlers = filterContent)
htmlTreeParse(nyt_review3, handlers = filterContent)
htmlTreeParse(nyt_review3)
getContent <- function() {
links <- character()
list(a = function(node, ...) {
links <<- c(links, xmlGetAttr(node, "p"))
node
},
links = function()links)
}
filterContent <- getContent()
htmlTreeParse(nyt_review3, handlers = filterContent)
df_contents <- data.frame(filterContent$links())
filterContent <- getContent()
htmlTreeParse(nyt_review3, handlers = filterContent)
df_contents <- data.frame(filterContent$links())
content_review = htmlParse(nyt_review3, asText=TRUE)
plain.text <- xpathSApply(content_reciew, "//p", xmlValue)
content_review = htmlParse(nyt_review3, asText=TRUE)
plain.text <- xpathSApply(content_review, "//p", xmlValue)
plain.text
cat(paste(plain.text, collapse = "\n"))
library(RCurl)
library(XML)
# Extract review from NYT given URL
movie_url1 <- "http://www.nytimes.com/2016/04/22/movies/review-the-huntsman-a-study-in-hollywoods-overstuffed-playbook.html"
movie_url2 <- "http://www.nytimes.com/glogin?URI=http%3A%2F%2Fwww.nytimes.com%2F2016%2F04%2F22%2Fmovies%2Freview-the-huntsman-a-study-in-hollywoods-overstuffed-playbook.html%3F_r%3D0"
movie_url3 <- "http://www.nytimes.com/2016/04/22/movies/review-the-huntsman-a-study-in-hollywoods-overstuffed-playbook.html?_r=0"
nyt_review1 <- getURL(movie_url1, ssl.verifypeer = FALSE, verbose = TRUE)
nyt_review2 <- getURL(movie_url2, cookie = "RMID=007f01010f90572928190004;Path=/; Domain=.nytimes.com;Expires=Wed, 03 May 2017 22:37:13 UTC", ssl.verifypeer = FALSE, verbose = TRUE)
nyt_review3 <- getURL(movie_url3, cookie = "NYT-S=0MCtDYyfcZCt7DXrmvxADeHxv7MvfmuFpYdeFz9JchiAIUFL2BEX5FWcV.Ynx4rkFI; expires=Thu, 02-Jun-2016 22:38:17 GMT; path=/; domain=.nytimes.com",
ssl.verifypeer = FALSE, verbose = TRUE)
nyt_review1 <- getURL(movie_url1)
nyt_review1
nyt_review1 <- getURL(movie_url1, verbose = TRUE)
myURL <- "http://www.nytimes.com/2016/04/22/movies/review-the-huntsman-a-study-in-hollywoods-overstuffed-playbook.html"
agent <- c(R.version$version.string, ",", R.version$platform)
movie_url <- "http://www.nytimes.com/2016/04/22/movies/review-the-huntsman-a-study-in-hollywoods-overstuffed-playbook.html"
#myURL <- "http://www.bluenile.com/api/public/loose-diamond/diamond-details/panel?country=USA&currency=USD&language=en-us&productSet=BN&sku=LD04077082"
agent <- c(R.version$version.string, ",", R.version$platform)
#Set RCurl pars
curl = getCurlHandle()
curlSetOpt(cookiejar="cookies.txt",  useragent = agent, followlocation = TRUE, curl=curl)
my_movie <- getURL(movie_url, curl = curl, verbose = TRUE)
my_movie
library(jsonlite)
library(knitr)
#RESULTS 0-20 AS OF 2016-05-01
NYTREVIEWS_JSON_URL1 = 'http://api.nytimes.com/svc/movies/v2/reviews/search.json?opening-date=2016-04-21;2016-05-018&api-key=YOURAPIKEYHERE'#url for api results 0-20
json_file1 <- fromJSON(NYTREVIEWS_JSON_URL1)# get json
df1 <- as.data.frame(json_file1$results) #dataframe for results
#str(df1) #view structure
#colnames(df1) #view column names
df1s<-df1[,c(1:8)] #subset needed columns
#RESULTS 21-40 AS OF 2016-05-01
NYTREVIEWS_JSON_URL2 = 'http://api.nytimes.com/svc/movies/v2/reviews/search.json?opening-date=2016-04-21;2016-05-01&api-key=YOURAPIKEYHERE&offset=20' #url for api results 20-40
json_file2 <- fromJSON(NYTREVIEWS_JSON_URL2) #get json
df2 <- as.data.frame(json_file2$results) #dataframe for results
df2s<-df2[,c(1:8)] #subset needed columns
#ALL RESULTS 0-40 COMBINED
df<- rbind(df1s,df2s) #combine all results
#knitr::kable(df, row.names =TRUE) #test
#ADD URL COLUMN TO RESULTS
url1 <- json_file1$results$link #collect links part 1
url1<-url1[,c(1:2)] #subset links
url2 <- json_file2$results$link #collect links part 2
url2<-url2[,c(1:2)] #subset links
#str(url1) #test
urls<- rbind(url1,url2) #combine all results for links
#knitr::kable(urls, row.names = TRUE) #test
combo<-cbind(df,urls) #combine reviews and links
combo<-combo[,c(1:3,7,8,10)] #subset needed columns
combo<-combo[,c(1,5,4,6,2,3)] #reorder needed columns
kable(combo, row.names = TRUE) #display with row numbers
#required libraries
library(jsonlite)
library(knitr)
#RESULTS 0-20 AS OF 2016-05-01
NYTREVIEWS_JSON_URL1 = 'http://api.nytimes.com/svc/movies/v2/reviews/search.json?opening-date=2016-04-21;2016-05-018&api-key=971b11ea372d3abc7c9bb7d914767aad:0:65677168'#url for api results 0-20
json_file1 <- fromJSON(NYTREVIEWS_JSON_URL1)# get json
df1 <- as.data.frame(json_file1$results) #dataframe for results
#str(df1) #view structure
#colnames(df1) #view column names
df1s<-df1[,c(1:8)] #subset needed columns
#RESULTS 21-40 AS OF 2016-05-01
NYTREVIEWS_JSON_URL2 = 'http://api.nytimes.com/svc/movies/v2/reviews/search.json?opening-date=2016-04-21;2016-05-01&api-key=971b11ea372d3abc7c9bb7d914767aad:0:65677168&offset=20' #url for api results 20-40
json_file2 <- fromJSON(NYTREVIEWS_JSON_URL2) #get json
df2 <- as.data.frame(json_file2$results) #dataframe for results
df2s<-df2[,c(1:8)] #subset needed columns
#ALL RESULTS 0-40 COMBINED
df<- rbind(df1s,df2s) #combine all results
#knitr::kable(df, row.names =TRUE) #test
#ADD URL COLUMN TO RESULTS
url1 <- json_file1$results$link #collect links part 1
url1<-url1[,c(1:2)] #subset links
url2 <- json_file2$results$link #collect links part 2
url2<-url2[,c(1:2)] #subset links
#str(url1) #test
urls<- rbind(url1,url2) #combine all results for links
#knitr::kable(urls, row.names = TRUE) #test
combo<-cbind(df,urls) #combine reviews and links
combo<-combo[,c(1:3,7,8,10)] #subset needed columns
combo<-combo[,c(1,5,4,6,2,3)] #reorder needed columns
kable(combo, row.names = TRUE) #display with row numbers
NYTREVIEWS_JSON_URL1 = 'http://api.nytimes.com/svc/movies/v2/reviews/search.json?opening-date=2016-04-21;2016-05-018&api-key=971b11ea372d3abc7c9bb7d914767aad:0:65677168'#url for api results 0-20
json_file1 <- fromJSON(NYTREVIEWS_JSON_URL1)# get json
df1 <- as.data.frame(json_file1$results)
NYTREVIEWS_JSON_URL1 = 'http://api.nytimes.com/svc/movies/v2/reviews/search.json?opening-date=2016-04-21;2016-05-018&api-key=971b11ea372d3abc7c9bb7d914767aad:0:65677168'
json_file1 <- fromJSON(NYTREVIEWS_JSON_URL1)
NYTREVIEWS_JSON_URL1 = 'http://api.nytimes.com/svc/movies/v2/reviews/search.json?opening-date=2016-04-21;2016-05-01&api-key=971b11ea372d3abc7c9bb7d914767aad:0:65677168'
json_file1 <- fromJSON(NYTREVIEWS_JSON_URL1)# get json
df1 <- as.data.frame(json_file1$results) #dataframe for results
#str(df1) #view structure
#colnames(df1) #view column names
df1s<-df1[,c(1:8)] #subset needed columns
#RESULTS 21-40 AS OF 2016-05-01
NYTREVIEWS_JSON_URL2 = 'http://api.nytimes.com/svc/movies/v2/reviews/search.json?opening-date=2016-04-21;2016-05-01&api-key=971b11ea372d3abc7c9bb7d914767aad:0:65677168&offset=20' #url for api results 20-40
json_file2 <- fromJSON(NYTREVIEWS_JSON_URL2) #get json
df2 <- as.data.frame(json_file2$results) #dataframe for results
df2s<-df2[,c(1:8)] #subset needed columns
#ALL RESULTS 0-40 COMBINED
df<- rbind(df1s,df2s) #combine all results
#knitr::kable(df, row.names =TRUE) #test
#ADD URL COLUMN TO RESULTS
url1 <- json_file1$results$link #collect links part 1
url1<-url1[,c(1:2)] #subset links
url2 <- json_file2$results$link #collect links part 2
url2<-url2[,c(1:2)] #subset links
#str(url1) #test
urls<- rbind(url1,url2) #combine all results for links
#knitr::kable(urls, row.names = TRUE) #test
combo<-cbind(df,urls) #combine reviews and links
combo<-combo[,c(1:3,7,8,10)] #subset needed columns
combo<-combo[,c(1,5,4,6,2,3)] #reorder needed columns
kable(combo, row.names = TRUE) #display with row numbers
str(combo)
library(RCurl)
library(XML)
length(combo$url)
combo$url[1]
install.packages("indicoio")
movie_score <- data.frame()
movie_score <- data.frame(, row.names = 'score')
movie_score <- data.frame(0, row.names = 'score')
movie_score
movie_score <- data.frame(0, column.names = 'score')
movie_score
movie_score <- data.frame()
setwd("~/GitHub/Data607FinalProject")
library(RCurl)
library(XML)
library(dplyr)
library(indicoio)
setwd("~/GitHub/Data607FinalProject")
tweets_url <- getURL("https://raw.githubusercontent.com/spsstudent15/Data607FinalProject/master/tweets503to509.csv")
tweets_list <- read.csv(text = tweets_url, header = TRUE, sep = ",")
movie_df <- read.csv("movie_score_nyt.csv", header = TRUE, sep = ",")
movie_score_nyt <- read.csv("movie_score_nyt.csv", header = TRUE, sep = ",")
my_data_raw <- inner_join(tweets_list, movie_score_nyt, by = "movie")
my_data_raw$city[my_data_raw$city == 'los Angeles'] <- 'Los Angeles'
nyt_false_positive <- movie_df %>% filter(Sentiment_Score_nyt < 0.75 & critics_pick == 1) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_false_negative <- movie_df %>% filter(Sentiment_Score_nyt >= 0.75 & critics_pick == 0) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_true_negative <- movie_df %>% filter(Sentiment_Score_nyt < 0.75 & critics_pick == 0) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_false_positive <- movie_df %>% filter(Sentiment_Score_nyt >= 0.75 & critics_pick == 1) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_false_positive
nyt_false_positive <- movie_score_nyt %>% filter(Sentiment_Score_nyt < 0.75 & critics_pick == 1) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_false_negative <- movie_score_nyt %>% filter(Sentiment_Score_nyt >= 0.75 & critics_pick == 0) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_true_negative <- movie_score_nyt %>% filter(Sentiment_Score_nyt < 0.75 & critics_pick == 0) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_false_positive <- movie_score_nyt %>% filter(Sentiment_Score_nyt >= 0.75 & critics_pick == 1) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_false_positive
movie_score_nyt
movie_score_nyt %>% filter(Sentiment_Score_nyt < 0.75 & critics_pick == 1)
movie_score_nyt %>% filter(Sentiment_Score_nyt < 0.75 & critics_pick == 1) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_false_positive <- movie_score_nyt %>% filter(Sentiment_Score_nyt < 0.75 & critics_pick == 1) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_false_positive <- movie_score_nyt %>% filter(Sentiment_Score_nyt < 0.75 & critics_pick == 1) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_false_positive <- movie_score_nyt %>% filter(Sentiment_Score_nyt < 0.75 & critics_pick == 1) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_false_negative <- movie_score_nyt %>% filter(Sentiment_Score_nyt >= 0.75 & critics_pick == 0) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_true_negative <- movie_score_nyt %>% filter(Sentiment_Score_nyt < 0.75 & critics_pick == 0) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_true_positive <- movie_score_nyt %>% filter(Sentiment_Score_nyt >= 0.75 & critics_pick == 1) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_false_positive
nyt_false_negative
nyt_true_negative <- movie_score_nyt %>% filter(Sentiment_Score_nyt < 0.75 & critics_pick == 0) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_true_negative <- movie_score_nyt %>% filter(Sentiment_Score_nyt < 0.75 & critics_pick == 0) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_true_negative
nyt_true_positive
nrow(nyt_false_positive)/nrow(movie_score_nyt)
nrow(nyt_false_positive)/nrow(movie_score_nyt) * 100
nyt_false_negative <- movie_score_nyt %>% filter(Sentiment_Score_nyt < 0.75 & critics_pick == 1) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_false_positive <- movie_score_nyt %>% filter(Sentiment_Score_nyt >= 0.75 & critics_pick == 0) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_true_negative <- movie_score_nyt %>% filter(Sentiment_Score_nyt < 0.75 & critics_pick == 0) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nyt_true_positive <- movie_score_nyt %>% filter(Sentiment_Score_nyt >= 0.75 & critics_pick == 1) %>%
select(movie, mpaa_rating, genre, Sentiment_Score_nyt, critics_pick)
nrow(nyt_false_positive)/nrow(movie_score_nyt) * 100
nrow(nyt_false_negative)/nrow(movie_score_nyt) * 100
nrow(nyt_true_negative)/nrow(movie_score_nyt) * 100
nrow(nyt_true_positive)/nrow(movie_score_nyt) * 100
