---
title: "Data 607 Final Project"
output: html_document
---

## Twitter search

Need to run only this chunk (`Twitter Setup`) first because you need to put in a PIN given by Twitter.  

```{r, Twitter Setup}
library(twitteR)
library(httr)
library(ROAuth)

consumer_key <- "needs_keys_from_slack"
consumer_secret <- "needs_keys_from_slack"
access_token <- "needs_keys_from_slack"
access_secret <- "needs_keys_from_slack"

download.file(url='http://curl.haxx.se/ca/cacert.pem', destfile='cacert.pem')
reqURL <- 'https://api.twitter.com/oauth/request_token'
accessURL <- 'https://api.twitter.com/oauth/access_token'
authURL <- 'https://api.twitter.com/oauth/authorize'
Cred <- OAuthFactory$new(consumerKey=consumer_key,
                         consumerSecret=consumer_secret,
                         requestURL=reqURL,
                         accessURL=accessURL,
                         authURL=authURL)

Cred$handshake(cainfo = system.file('CurlSSL', 
                                    'cacert.pem', 
                                    package = 'RCurl'))
```

Now run the following chunks after entering the PIN for Twitter Authorization.

```{r}
save(Cred, file='twitter authentication.Rdata')
load('twitter authentication.Rdata') 
setup_twitter_oauth(consumer_key, 
                    consumer_secret, 
                    access_token, 
                    access_secret)
```

This chunk gets the twitter search results for a term, `searchTwitter` has some other settings that could probably improve results.

```{r, eval=FALSE}
#required libraries
library(jsonlite)
library(knitr)

#RESULTS 0-20 AS OF 2016-05-01
NYTREVIEWS_JSON_URL1 = 'http://api.nytimes.com/svc/movies/v2/reviews/search.json?openingmurl1-date=2016-04-21;2016-05-018&api-key=YOURAPIKEYHERE'#url for api results 0-20
json_file1 <- fromJSON(NYTREVIEWS_JSON_URL1)# get json
df1 <- as.data.frame(json_file1$results) #dataframe for results
#str(df1) #view structure 
#colnames(df1) #view column names
df1s<-df1[,c(1:8)] #subset needed columns

#RESULTS 21-40 AS OF 2016-05-01
NYTREVIEWS_JSON_URL2 = 'http://api.nytimes.com/svc/movies/v2/reviews/search.json?opening-date=2016-04-21;2016-05-01&api-key=YOURAPIKEYHERE&offset=20' #url for api results 20-40
json_file2 <- fromJSON(NYTREVIEWS_JSON_URL2) #get json
df2 <- as.data.frame(json_file2$results) #dataframe for results
df2s<-df2[,c(1:8)] #subset needed columns

#ALL RESULTS 0-40 COMBINED
df<- rbind(df1s,df2s) #combine all results
#knitr::kable(df, row.names =TRUE) #test

#ADD URL COLUMN TO RESULTS
url1 <- json_file1$results$link #collect links part 1
url1<-url1[,c(1:2)] #subset links
url2 <- json_file2$results$link #collect links part 2
url2<-url2[,c(1:2)] #subset links
#str(url1) #test
urls<- rbind(url1,url2) #combine all results for links
#knitr::kable(urls, row.names = TRUE) #test
combo<-cbind(df,urls) #combine reviews and links
combo<-combo[,c(1:3,7,8,10)] #subset needed columns
combo<-combo[,c(1,5,4,6,2,3)] #reorder needed columns
kable(combo, row.names = TRUE) #display with row numbers
```


```{r, echo=FALSE}

library(jsonlite)
library(knitr)

#RESULTS 0-20 AS OF 2016-05-01

NYTREVIEWS_JSON_URL1 = 'http://api.nytimes.com/svc/movies/v2/reviews/search.json?openingmurl1-date=2016-04-21;2016-05-018&api-key=ef056a1d0cdde8b2f03c95bc7dd57722:19:29126896'
json_file1 <- fromJSON(NYTREVIEWS_JSON_URL1)
df1 <- as.data.frame(json_file1$results)
#str(df1)
#colnames(df1)
df1s<-df1[,c(1:8)]


#RESULTS 21-40 AS OF 2016-05-01

NYTREVIEWS_JSON_URL2 = 'http://api.nytimes.com/svc/movies/v2/reviews/search.json?opening-date=2016-04-21;2016-05-01&api-key=ef056a1d0cdde8b2f03c95bc7dd57722:19:29126896&offset=20'
json_file2 <- fromJSON(NYTREVIEWS_JSON_URL2)
df2 <- as.data.frame(json_file2$results)
df2s<-df2[,c(1:8)]


df<- rbind(df1s,df2s)
#knitr::kable(df, row.names =TRUE)



url1 <- json_file1$results$link
url1<-url1[,c(1:2)]

url2 <- json_file2$results$link
url2<-url2[,c(1:2)]

#str(url1)
urls<- rbind(url1,url2)
#knitr::kable(urls, row.names = TRUE)

combo<-cbind(df,urls)
combo<-combo[,c(1:3,7,8,10)]
combo<-combo[,c(1,5,4,6,2,3)]
kable(combo, row.names = TRUE)
```

```{r, include= FALSE}
url <- "https://raw.githubusercontent.com/spsstudent15/Data607FinalProject/master/"
```

```{r}
data.url <- file(paste(url,"locations.csv", sep = ""), open="r" )
locations <- read.csv(data.url, sep=",", header=TRUE, stringsAsFactors = FALSE)
```


```{r, Searching Twitter}
library(indicoio)

rm_special <-function(x) iconv(x, "UTF-8", "UTF-8",sub='')

search_term <- function(term){
                  require(magrittr)
                  search_term <- gsub(" ", "+", term) %>%
                                 paste("+movie", sep = "")
                  return(search_term)
                }

df <- NULL
for (i in combo$display_title){
  SearchTerm <- search_term(i)
  for (j in seq(1:length(locations$City))){
      list <- suppressWarnings(searchTwitter(SearchTerm,  n = 5000, 
                                    geocode = paste(locations$Lat[j], ",", locations$Long[j], ",30mi", sep = "" )))
          if (length(list) == 0){ 
            NULL
          } else { 
          tweetdf <- twListToDF(list)
          tweetdf <- as.data.frame(unique(tweetdf$text))
          colnames(tweetdf) <- c("tweet")
          tweetdf$city <- locations$City[j]
          tweetdf$movie <- as.character(i)
          tweetdf$day <- format(Sys.Date() ,format="%m.%d.%Y")
          df <- rbind(df,tweetdf)
          }
  } 
}
df$Sentiment_Score <- unlist(sentiment(as.character(rm_special(df$tweet)), 
                                       api_key = '114ffc17022fd58af3da5cfd5f3e4388'))
write.csv(df, file = paste("Tweets for ", as.character(format(Sys.Date() ,format="%m.%d.%Y")), ".csv", sep = ""))


```

